{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch_8_adding memory_capacity.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO1xx3zHnXWfubOZZuWcSpS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sshubam/PyTorch-Code/blob/main/PyTorch_8_adding_memory_capacity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX8iDLCihPYH"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.functional as F"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4z4VNZS8Trk"
      },
      "source": [
        "# Defining different types of models dynamically\n",
        "*These all are for img recognition*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y570ZO_Qi0-3"
      },
      "source": [
        "class NetWidth(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "    self.conv2 = nn.Conv2d(32, 16, kernel_Size=3, padding=1)\n",
        "    self.fc1 = nn.Linear(16*8*8, 32)  #fc1 stands for fully connected 1\n",
        "    self.fc2 = nn.Linear(32, 2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
        "    out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
        "    out = out.view(-1, 16*8*8)\n",
        "    out = torch.tanh(self.fc1(out))\n",
        "    out = self.fc2(out)\n",
        "    return out"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba9DAHp6pPSB"
      },
      "source": [
        "class NetWidth(nn.Module):\n",
        "  def __init__(self, n_chans1=32):\n",
        "    super().__init__()\n",
        "    self.n_chans1 = n_chans1\n",
        "    self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
        "    self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3, padding=1)\n",
        "    self.fc1 = nn.Linear(8*8*n_chans1 // 2, 32)\n",
        "    self.fc2 = nn.Linear(32, 2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
        "    out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
        "    out = out.view(-1, 8*8*self.n_chans1//2)\n",
        "    out = torch.tanh(self.fc1(out))\n",
        "    return out "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zD7OAiXsoJH"
      },
      "source": [
        "model = NetWidth()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOKUKZ2orXXF",
        "outputId": "b0c690e3-3523-43dc-80ba-01cd5c8059f2"
      },
      "source": [
        "sum(p.numel() for p in model.parameters())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38386"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qtWr5ULxTed"
      },
      "source": [
        "def training_loop_l2_reg(n_epochs, optimizer, model, loss_fn, train_laoder):\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "    loss_train = 0.0\n",
        "    for imgs, labels in train_loader:\n",
        "      imgs = imgs.to(device=device)\n",
        "      labels = labels.to(device=device)\n",
        "      outputs = model(imgs)\n",
        "      loss = loss_fn(outputs, labels)\n",
        "\n",
        "      l2_lambda = 0.001\n",
        "      l2_norm = sum(p.pow(2.0).sum()\n",
        "                    for p in model.parameters())\n",
        "      loss = loss + l2_lambda * l2_norm\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      loss_train +=loss.item()\n",
        "\n",
        "    if epoch == 1 or epoch % 10 == 0:\n",
        "      print('{} Epoch {}, Training Loss {}'.format(datetime.datetime.now(), epoch, loss_train / len(train_loader)))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dCU9g6LDKjN"
      },
      "source": [
        "class NetDropout(nn.Module):\n",
        "  def __init__(self, n_chans1=32):\n",
        "    super().__init__()\n",
        "    self.n_chans1 = n_chans1\n",
        "    self.conv1 = nn.Conv2d(3, n_chans, kernel_size=3, padding=1)\n",
        "    self.conv1_dropout = nn.Dropout2d(p=0.4)\n",
        "    self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3, padding=1)\n",
        "    self.conv2_dropout = nn.Dropout2d(p=0.4)\n",
        "    self.fc1 = nn.Linear(8*8*n_chans1 // 2, 32)\n",
        "    self.fc2 = nn.Linear(32, 2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
        "    out = self.conv1_dropout(out)\n",
        "    out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
        "    out = self.conv2_dropout(out)\n",
        "    out = out.view(-1, 8*8*self.n_chans1 // 2)\n",
        "    out = torch.tanh(self.fc1(out))\n",
        "    out = self.fc2(out)\n",
        "    return out"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMsKEeLOmhvo"
      },
      "source": [
        "class NetBatchNorm(nn.Module):\n",
        "  def __init__(self, n_chans1=32):\n",
        "    super().__init__()\n",
        "    self.n_chans1 = n_chans1\n",
        "    self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
        "    self.conv1_batchnorm = nn.BatchNorm2d(num_features=n_chans1)\n",
        "    self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3,\n",
        "    padding=1)\n",
        "    self.conv2_batchnorm = nn.BatchNorm2d(num_features=n_chans1 // 2)\n",
        "    self.fc1 = nn.Linear(8 * 8 * n_chans1 // 2, 32)\n",
        "    self.fc2 = nn.Linear(32, 2)\n",
        "  def forward(self, x):\n",
        "    out = self.conv1_batchnorm(self.conv1(x))\n",
        "    out = F.max_pool2d(torch.tanh(out), 2)\n",
        "    out = self.conv2_batchnorm(self.conv2(out))\n",
        "    out = F.max_pool2d(torch.tanh(out), 2)\n",
        "    out = out.view(-1, 8 * 8 * self.n_chans1 // 2)\n",
        "    out = torch.tanh(self.fc1(out))\n",
        "    out = self.fc2(out)\n",
        "    return out"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CIRmjk4ZI7u"
      },
      "source": [
        "class NetDepth(nn.Module):\n",
        "  def __init__(self, n_chans1=32):\n",
        "    super().__init__()\n",
        "    self.n_chans1 = n_chans1\n",
        "    self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
        "    self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3, padding=1)\n",
        "    self.conv3 = nn.Conv2d(n_chans1 // 2, n_chans1 // 2, kernel_size=3, padding=1)\n",
        "    self.fc1 = nn.Linear(4*4*n_chans1 // 2, 32)\n",
        "    self.fc2 = nn.Linear(32, 2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
        "    out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
        "    out = F.max_pool2d(torch.relu(self.conv3(out)), 2)\n",
        "    out = out.view(-1, 4*4*self.n_chans1 // 2)\n",
        "    out = torch.relu(self.fc1(out))\n",
        "    out = self.fc2(out)\n",
        "    return out"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoKVbLbKbhF5"
      },
      "source": [
        "class NetRes(nn.Module):  #also called the ResNet\n",
        "  def __init__(self, n_chans1=32):\n",
        "    super().__init__()\n",
        "    self.n_chans1 = n_chans1\n",
        "    self.conv1 = nn.Conv2d(3, n_chans1)\n",
        "    self.conv2 = n.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3, padding=1)\n",
        "    self.conv3 = nn.Conv2d(n_chans1 // 2, n_chans1 // 2, kernel_size=3, padding=1)\n",
        "    self.fc1 = nn.Linear(4*4*n_chans1 // 2, 32)\n",
        "    self.fc2 = nn.Linear(32, 2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
        "    out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
        "    out1 = out \n",
        "    out = F.max_pool2d(torch.relu(self.conv3(out)) + out1, 2)\n",
        "    out = out.view(-1, 4*4*self.n_chans1) // 2\n",
        "    out = torch.relu(self.fc1(out))\n",
        "    out = self.fc2(out)\n",
        "    return out"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC0TDUSfrSTV"
      },
      "source": [
        "class ResBlock(nn.Module):\n",
        "  def __init__(self, n_chans):\n",
        "    super(ResBlock, self).__init__()\n",
        "    self.conv = nn.Conv2d(n_chans, n_chans, kernel_size=3,\n",
        "    padding=1, bias=False)\n",
        "    self.batch_norm = nn.BatchNorm2d(num_features=n_chans)\n",
        "    torch.nn.init.kaiming_normal_(self.conv.weight,nonlinearity='relu')\n",
        "    torch.nn.init.constant_(self.batch_norm.weight, 0.5)\n",
        "    torch.nn.init.zeros_(self.batch_norm.bias)\n",
        "  def forward(self, x):\n",
        "    out = self.conv(x)\n",
        "    out = self.batch_norm(out)\n",
        "    out = torch.relu(out)\n",
        "    return out + x"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43PH_C3_3pHb"
      },
      "source": [
        "class NetResDeep(nn.Module):\n",
        "  def __init__(self, n_chans1=32, n_blocks=10):\n",
        "    super().__init__()\n",
        "    self.n_chans1 = n_chans1\n",
        "    self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
        "    self.resblocks = nn.Sequential(*(n_blocks * [ResBlock(n_chans=n_chans1)]))\n",
        "    self.fc1 = nn.Linear(8*8*n_chans1, 32)\n",
        "    self.fc2 = nn.Linear(32, 2)\n",
        "\n",
        "  def forward(Self, x):\n",
        "    out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
        "    out = self.resblocks(out)\n",
        "    out = F.max_pool2d(out, 2)\n",
        "    out = out.view(-1, 8*8*self.n_chans1)\n",
        "    out = torch.relu(self.fc1(out))\n",
        "    out = self.fc2(out)\n",
        "    return out"
      ],
      "execution_count": 12,
      "outputs": []
    }
  ]
}